
"""
2026 MCM/ICM Problem C - Q1 (ä¼˜åŒ–ç‰ˆï¼Œä¸­æ–‡æ³¨é‡Š)

ä½ å°†å¾—åˆ°ï¼š
1) q1_df_votes.csv  : æ¯ä¸ª season-week-é€‰æ‰‹ çš„åæ¨æŠ•ç¥¨ä»½é¢ vote_shareã€åˆæˆç»“æœï¼ˆé€‚é… Rank/Percentageï¼‰
2) q1_metrics.csv   : æ¯ä¸ª season-week çš„ä¸€è‡´æ€§æŒ‡æ ‡ï¼ˆacc_single / cover_bottomk / jaccard / delta_marginï¼‰
3) q1_elim_by_week.csv : ä»æ•°æ®æ¨æ–­çš„æ¯å‘¨æ·˜æ±°åå• true_elimsï¼ˆé›†åˆå·®åˆ†æ³•ï¼‰
4) q1_elim_people.csv  : æ¯ä½é€‰æ‰‹æœ€åå­˜æ´»å‘¨ã€æ˜¯å¦å†³èµ›ç»“æŸï¼ˆç”¨äºå¤æ ¸ï¼‰

æ ¸å¿ƒæ€æƒ³ï¼ˆå†™æŠ¥å‘Šæ—¶å¯ç”¨ï¼‰ï¼š
- è§‚ä¼—æŠ•ç¥¨ä¸ºæ½œå˜é‡ï¼›å¯è¯†åˆ«çš„æ˜¯â€œç›¸å¯¹æŠ•ç¥¨ä»½é¢â€è€Œéç»å¯¹ç¥¨æ•°ï¼›
- æ¯å‘¨ç”¨ MAPï¼ˆæœ€å¤§åéªŒï¼‰åæ¼” vote_shareï¼š
  * softmax(x) ä½œä¸ºæŠ•ç¥¨ä»½é¢ï¼ˆéè´Ÿä¸”å’Œä¸º1ï¼‰
  * x æ¥è¿‘å…ˆéªŒä¸­å¿ƒ muï¼ˆç”± Ridge ç”Ÿæˆï¼‰+ L2 æ­£åˆ™é¿å…æç«¯
  * ç”¨â€œæ¦‚ç‡æ·˜æ±°æŸå¤±â€ï¼ˆsoftmin likelihoodï¼‰é¼“åŠ±å¤ç°çœŸå®æ·˜æ±°
- è‡ªåŠ¨æŒ‰ season åˆ‡æ¢èµ›åˆ¶ï¼ˆRank vs Percentageï¼‰
- ç”¨ä¸Šä¸€å‘¨ x_hat åšæ—¶é—´å¹³æ»‘ä¸ warm startï¼ˆè®©ç¥¨ä»½é¢éšå‘¨æ›´å¹³æ»‘ã€æ›´ç¨³ï¼‰

ä¾èµ–ï¼š
pip install numpy pandas scipy scikit-learn
"""

import os
import re
import numpy as np
import pandas as pd
from scipy.optimize import minimize
from sklearn.linear_model import Ridge
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# ===================== ä½ éœ€è¦æ”¹çš„ä¸¤ä¸ªå‚æ•° =====================
# Windows è·¯å¾„å»ºè®®å†™æˆï¼šCSV_PATH = r"C:\_Am\Data.csv"
CSV_PATH = r"/mnt/data/2026_MCM_Problem_C_Data.csv"
OUT_DIR  = r"/mnt/data/q1_outputs_test"
# ============================================================

# æ˜¯å¦è¾“å‡º Excelï¼ˆåŒå .xlsxï¼‰ï¼Œé»˜è®¤ Falseï¼ˆCSV è¶³å¤Ÿï¼‰
SAVE_EXCEL = False

# Step5ï¼ˆå¯é€‰ï¼‰ï¼šbootstrap ä¸ç¡®å®šæ€§ï¼ˆåªå»ºè®®å¯¹å°‘æ•°å‘¨åšï¼‰
RUN_BOOTSTRAP = False
BOOTSTRAP_SEASON = 1
BOOTSTRAP_WEEK   = 1
BOOTSTRAP_B = 200

# è¾“å‡ºç¼–ç ï¼ˆWindows Excel å‹å¥½ï¼‰
CSV_ENCODING = "utf-8-sig"


# ------------------------------------------------------------
# å·¥å…·ï¼šå®‰å…¨ä¿å­˜
# ------------------------------------------------------------
def ensure_dir(path: str):
    os.makedirs(path, exist_ok=True)

def save_csv(df: pd.DataFrame, filepath: str):
    df.to_csv(filepath, index=False, encoding=CSV_ENCODING)

def save_excel(df: pd.DataFrame, filepath: str, sheet_name: str = "sheet1"):
    # åªåœ¨éœ€è¦æ—¶å†™ xlsxï¼ˆé¿å…é¢å¤–å¼€é”€ï¼‰
    with pd.ExcelWriter(filepath, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)


# ============================================================
# Step 0ï¼šè¯»å–å®½è¡¨ + å®½è½¬é•¿
# ============================================================
def load_raw(csv_path: str) -> pd.DataFrame:
    """
    è¾“å…¥ï¼šå®½è¡¨ï¼ˆåŒ…å« week1_judge1_score ...ï¼‰
    è¾“å‡ºï¼šé•¿è¡¨ï¼ˆæ¯è¡Œæ˜¯ä¸€æ¡ season-week-é€‰æ‰‹-è¯„å§” çš„è¯„åˆ†ï¼‰
    """
    df = pd.read_csv(csv_path)

    # å¿…éœ€åˆ—æ£€æŸ¥ï¼ˆé¿å…â€œåˆ—åä¸ä¸€è‡´â€å¯¼è‡´é™é»˜é”™è¯¯ï¼‰
    base_cols = [
        "celebrity_name",
        "ballroom_partner",
        "celebrity_industry",
        "celebrity_homestate",
        "celebrity_homecountry/region",
        "celebrity_age_during_season",
        "season",
        "results",
        "placement",
    ]
    missing = [c for c in base_cols if c not in df.columns]
    if missing:
        raise ValueError(f"CSV ç¼ºå°‘å¿…è¦åˆ—ï¼š{missing}ã€‚è¯·æ£€æŸ¥åˆ—åæ˜¯å¦ä¸€è‡´ã€‚")

    # æ‰€æœ‰å‘¨-è¯„å§”åˆ†æ•°åˆ—
    score_cols = [c for c in df.columns if re.match(r"week\d+_judge\d+_score$", str(c))]
    if not score_cols:
        raise ValueError("CSV ä¸­æ²¡æ‰¾åˆ° week1_judge1_score è¿™ç§åˆ—åï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ã€‚")

    # å®½è½¬é•¿
    long = df[base_cols + score_cols].melt(
        id_vars=base_cols,
        value_vars=score_cols,
        var_name="wk_judge",
        value_name="score",
    )

    # è§£æ week/judge
    m = long["wk_judge"].str.extract(r"week(?P<week>\d+)_judge(?P<judge>\d+)_score")
    long["week"] = m["week"].astype(int)
    long["judge"] = m["judge"].astype(int)
    long.drop(columns=["wk_judge"], inplace=True)

    # åˆ†æ•°å¯èƒ½åŒ…å« 'N/A' ç­‰å­—ç¬¦ä¸²ï¼Œå¼ºåˆ¶è½¬ä¸ºæ•°å€¼ï¼Œæ— æ³•è½¬æ¢çš„è®°ä¸º NaN
    long["score"] = pd.to_numeric(long["score"], errors="coerce")

    return long


# ============================================================
# Step 0.5ï¼šæ„å»ºå‘¨è¡¨ï¼šè¯„å§”æ€»åˆ† J + alive æ ‡è®°
# ============================================================
def build_week_table(long_scores: pd.DataFrame) -> pd.DataFrame:
    """
    è¾“å‡º week_tblï¼šæ¯è¡Œæ˜¯ (season, week, celebrity_name) çš„å½“å‘¨ä¿¡æ¯
    - Jï¼šå½“å‘¨è¯„å§”æ€»åˆ†ï¼ˆNaN å¿½ç•¥ï¼‰
    - aliveï¼šJ>0 è§†ä¸ºå½“å‘¨ä»åœ¨æ¯”èµ›
    """
    week_tbl = (
        long_scores
        .groupby(["season", "week", "celebrity_name"], as_index=False)
        .agg(
            J=("score", lambda s: np.nansum(s.to_numpy())),
            ballroom_partner=("ballroom_partner", "first"),
            industry=("celebrity_industry", "first"),
            homestate=("celebrity_homestate", "first"),
            homecountry=("celebrity_homecountry/region", "first"),
            age=("celebrity_age_during_season", "first"),
            placement=("placement", "first"),
            results=("results", "first"),
        )
    )
    week_tbl["alive"] = (week_tbl["J"] > 0).astype(int)
    return week_tbl


# ============================================================
# Step 1ï¼šæ¨æ–­æ¯å‘¨æ·˜æ±°è€…ï¼ˆé›†åˆå·®åˆ†æ³•ï¼Œä¿®å¤â€œæœªæ’­å‡ºå‘¨â€é™·é˜±ï¼‰
# ============================================================
def infer_eliminations(week_tbl: pd.DataFrame):
    """
    å…³é”®ä¿®å¤ç‚¹ï¼š
    - å¾ˆå¤šèµ›å­£å¹¶é 11 å‘¨å…¨æ’­ï¼Œæœªæ’­å‡ºçš„å‘¨ä¼šå‡ºç°å…¨ NaN -> J=0 -> alive=0
    - å¦‚æœæŠŠè¿™äº›â€œæœªæ’­å‡ºå‘¨â€ä¹Ÿå½“ä½œ week åºåˆ—ï¼Œä¼šæŠŠå†³èµ›å‘¨è¯¯åˆ¤ä¸ºâ€œå¤§æ·˜æ±°â€
    è§£å†³ï¼š
    - weeks åªå–â€œå®é™…æ’­å‡ºå‘¨â€ï¼šè‡³å°‘æœ‰äºº alive==1 çš„ week
    - æ·˜æ±°é›†åˆ E_t = S_t \ S_nextï¼ˆä¸‹ä¸€åœºæ¯”èµ›å‘¨ï¼‰
    """
    rows = []
    season_last_rows = []

    for season, g in week_tbl.groupby("season"):
        # âœ… åªä¿ç•™â€œå®é™…æ’­å‡ºå‘¨â€ï¼ˆè‡³å°‘æœ‰äºº alive==1ï¼‰
        weeks = sorted(g[g["alive"] == 1]["week"].unique().tolist())
        if len(weeks) == 0:
            continue

        last_week = int(max(weeks))
        season_last_rows.append({"season": int(season), "season_last_week": last_week})

        # é€å‘¨å·®åˆ†ï¼ˆæœ€åä¸€å‘¨æ²¡æœ‰ nextï¼Œä¸æ¨æ·˜æ±°ï¼‰
        for idx in range(len(weeks) - 1):
            t = int(weeks[idx])
            t_next = int(weeks[idx + 1])

            S_t = set(g[(g["week"] == t) & (g["alive"] == 1)]["celebrity_name"].astype(str))
            S_next = set(g[(g["week"] == t_next) & (g["alive"] == 1)]["celebrity_name"].astype(str))

            elim = sorted(list(S_t - S_next))
            if elim:
                rows.append({"season": int(season), "week": t, "true_elims": elim})

    elim_by_week = pd.DataFrame(rows).sort_values(["season", "week"]).reset_index(drop=True)
    season_last = pd.DataFrame(season_last_rows).sort_values(["season"]).reset_index(drop=True)

    # é¢å¤–è¾“å‡ºï¼šæ¯ä¸ªé€‰æ‰‹æœ€åå­˜æ´»å‘¨ï¼ˆä¾¿äºå¤æ ¸ï¼‰
    last_alive = (
        week_tbl[week_tbl["alive"] == 1]
        .groupby(["season", "celebrity_name"])["week"]
        .max()
        .rename("last_alive_week")
        .reset_index()
    )
    elim_people = last_alive.merge(season_last, on="season", how="left")
    elim_people["is_finale_end"] = (elim_people["last_alive_week"] == elim_people["season_last_week"]).astype(int)

    # è‡ªæ£€ï¼šæœ€åæ’­å‡ºå‘¨ä¸åº”è¯¥å‡ºç°åœ¨ elim_by_week ä¸­ï¼ˆå¦åˆ™è¯´æ˜æ•°æ®/æ¨æ–­æœ‰é—®é¢˜ï¼‰
    if not elim_by_week.empty and not season_last.empty:
        tmp = elim_by_week.merge(season_last, on="season", how="left")
        bad = tmp[tmp["week"] >= tmp["season_last_week"]]
        if len(bad) > 0:
            print("âš ï¸ è­¦å‘Šï¼šå‘ç°æœ€åæ’­å‡ºå‘¨ä¹Ÿè¢«æ¨æ–­å‡ºæ·˜æ±°ï¼Œå¯èƒ½ä»æ··å…¥æœªæ’­å‡ºå‘¨æˆ–å‘¨åºä¸è¿ç»­ï¼š")
            print(bad.head(20))

    return season_last, elim_people, elim_by_week


# ============================================================
# Step 2ï¼šå…ˆéªŒä¸­å¿ƒ muï¼ˆRidgeï¼Œå¼±ç›‘ç£ proxyï¼‰
# ============================================================
def fit_prior_mu(week_tbl: pd.DataFrame):
    """
    å…ˆéªŒä¸­å¿ƒ mu çš„ä½œç”¨ï¼š
    - æŠ•ç¥¨ä¸å¯è¯†åˆ«ï¼šæ»¡è¶³æ·˜æ±°çš„æŠ•ç¥¨è§£æœ‰æ— ç©·å¤š
    - æˆ‘ä»¬ç”¨ mu æŒ‡å®šâ€œæ›´åˆç†/æ›´ä¿å®ˆâ€çš„ä¸­å¿ƒï¼Œè®©è§£ä¸ä¼šä¹±é£

    è®­ç»ƒä¿¡å·ï¼ˆå¼±ç›‘ç£ï¼‰ï¼š
      y0 = log(J + 1)

    ç‰¹å¾ï¼ˆå¯è§£é‡Šä¸”æ˜“è·‘ï¼‰ï¼š
    - æ•°å€¼ï¼šJã€ageã€week
    - ç±»åˆ«ï¼šindustryã€homecountryã€homestateã€ballroom_partner
    """
    df = week_tbl.copy()

    train = df[df["alive"] == 1].copy()
    y0 = np.log(train["J"].clip(lower=0) + 1.0)

    num_cols = ["J", "age", "week"]
    cat_cols = ["industry", "homecountry", "homestate", "ballroom_partner"]

    pre = ColumnTransformer(
        transformers=[
            ("num", "passthrough", num_cols),
            ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols),
        ],
        remainder="drop",
        sparse_threshold=0.3,
    )

    model = Ridge(alpha=1.0, random_state=0)
    pipe = Pipeline([("pre", pre), ("ridge", model)])
    pipe.fit(train, y0)

    df["mu"] = pipe.predict(df)
    return df, pipe


# ============================================================
# Step 3ï¼šæ¯å‘¨ MAP åæ¼” vote_shareï¼ˆèµ›åˆ¶è‡ªåŠ¨åˆ‡æ¢ + æ¦‚ç‡æ·˜æ±°æŸå¤± + æ—¶é—´å¹³æ»‘ï¼‰
# ============================================================
def softmax(x: np.ndarray) -> np.ndarray:
    """æŠŠä»»æ„å®æ•°å‘é‡æ˜ å°„ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼ˆéè´Ÿä¸”å’Œä¸º1ï¼‰"""
    x = np.asarray(x, dtype=float)
    x = x - np.max(x)
    ex = np.exp(x)
    return ex / (np.sum(ex) + 1e-12)

def season_rule(season: int) -> str:
    """
    èµ›åˆ¶åˆ‡æ¢ï¼ˆé¢˜é¢å¸¸è§è®¾å®šï¼‰ï¼š
    - Season 1-2 ä¸ 28+ï¼šRank
    - Season 3-27ï¼šPercentage
    """
    if season in (1, 2) or season >= 28:
        return "rank"
    return "percentage"

def soft_rank(values: np.ndarray, temp: float = 0.05) -> np.ndarray:
    """
    å¯å¾®â€œè½¯åæ¬¡â€ï¼ˆæ•°å€¼è¶Šå¤§è¶Šå¥½ -> åæ¬¡è¶Šå°è¶Šå¥½ï¼‰
      rank_i = 1 + sum_{j!=i} sigmoid((v_j - v_i)/temp)
    """
    v = np.asarray(values, dtype=float)
    diff = (v.reshape(1, -1) - v.reshape(-1, 1)) / max(temp, 1e-6)
    sig = 1.0 / (1.0 + np.exp(-diff))
    np.fill_diagonal(sig, 0.0)
    return 1.0 + np.sum(sig, axis=1)

class Q1Config:
    """
    lam: L2 æ­£åˆ™ï¼ˆé˜²æç«¯ï¼‰
    gamma: æ·˜æ±°ä¸€è‡´æ€§é¡¹æƒé‡ï¼ˆè¶Šå¤§è¶Šå¼ºåˆ¶å¤ç°æ·˜æ±°ï¼‰
    tau: æ¦‚ç‡æ·˜æ±°æ¸©åº¦ï¼ˆè¶Šå°è¶Šæ¥è¿‘ç¡¬çº¦æŸï¼‰
    rank_temp: soft-rank æ¸©åº¦ï¼ˆè¶Šå°è¶Šæ¥è¿‘çœŸå®åæ¬¡ï¼Œä½†æ¢¯åº¦æ›´å°–é”ï¼‰
    smooth_w: å‘¨é—´å¹³æ»‘æƒé‡ï¼ˆ0~1ï¼‰
    scaled_total_votes: ä»…ç”¨äºå±•ç¤ºï¼ˆå°†ä»½é¢ä¹˜ä¸€ä¸ªæ€»ç¥¨æ•°å°ºåº¦ï¼‰
    """
    def __init__(
        self,
        lam=0.1,
        gamma=120.0,
        tau=0.02,
        x_bounds=(-12, 12),
        rank_temp=0.05,
        smooth_w=0.30,
        scaled_total_votes=1_000_000,
    ):
        self.lam = lam
        self.gamma = gamma
        self.tau = tau
        self.x_bounds = x_bounds
        self.rank_temp = rank_temp
        self.smooth_w = smooth_w
        self.scaled_total_votes = scaled_total_votes

def compute_elim_score_and_extras(season: int, J: np.ndarray, vote_share: np.ndarray, cfg: Q1Config):
    """
    è¿”å›ï¼š
    - elim_scoreï¼šè¶Šå¤§è¡¨ç¤ºè¶Šâ€œå·®/æ›´å¯èƒ½æ·˜æ±°â€ï¼ˆç»Ÿä¸€æ ‡å‡†ï¼Œä¾¿äºæ’åï¼‰
      * Percentageï¼šelim_score = -Cï¼ˆCè¶Šå°è¶Šå·®ï¼‰
      * Rankï¼šelim_score = combined_rankï¼ˆåæ¬¡å’Œè¶Šå¤§è¶Šå·®ï¼‰
    - extrasï¼šç”¨äºå†™ä½œ/ç”»å›¾çš„ä¸­é—´é‡
    """
    rule = season_rule(int(season))
    J = np.asarray(J, dtype=float)
    vote_share = np.asarray(vote_share, dtype=float)

    if rule == "percentage":
        judge_share = J / (J.sum() + 1e-12)
        C = 0.5 * judge_share + 0.5 * vote_share
        elim_score = -C
        extras = {
            "rule": rule,
            "C": C,
            "judge_share": judge_share,
            "judge_rank": np.full_like(C, np.nan),
            "vote_rank": np.full_like(C, np.nan),
            "combined_rank": np.full_like(C, np.nan),
        }
        return elim_score, extras

    # Rank
    judge_rank = soft_rank(J, temp=cfg.rank_temp)
    vote_rank = soft_rank(vote_share, temp=cfg.rank_temp)
    combined_rank = 0.5 * judge_rank + 0.5 * vote_rank
    elim_score = combined_rank  # è¶Šå¤§è¶Šå·®

    extras = {
        "rule": rule,
        "C": np.full_like(combined_rank, np.nan),
        "judge_share": np.full_like(combined_rank, np.nan),
        "judge_rank": judge_rank,
        "vote_rank": vote_rank,
        "combined_rank": combined_rank,
    }
    return elim_score, extras

def elim_nll(elim_score: np.ndarray, elim_indices: list, tau: float) -> float:
    """
    æ¦‚ç‡æ·˜æ±°æŸå¤±ï¼ˆè´Ÿå¯¹æ•°ä¼¼ç„¶ï¼‰ï¼š
    å°†æ·˜æ±°è€…è§†ä¸ºä» softmax(elim_score/tau) æŠ½åˆ°çš„ç»“æœã€‚
    å¤šæ·˜æ±°å‘¨ï¼šå¯¹æ¯ä¸ªæ·˜æ±°è€… NLL å–å¹³å‡ï¼ˆç®€å•ç¨³å¥ï¼Œç«èµ›è¶³å¤Ÿç”¨ï¼‰
    """
    if not elim_indices:
        return 0.0

    z = np.asarray(elim_score, dtype=float) / max(tau, 1e-6)
    z = z - np.max(z)
    p = np.exp(z)
    p = p / (np.sum(p) + 1e-12)

    return float(np.mean([-np.log(p[i] + 1e-12) for i in elim_indices]))

def week_objective(x, mu_eff, J, season, elim_indices, cfg: Q1Config):
    """
    æ¯å‘¨ä¼˜åŒ–ç›®æ ‡ï¼š
    1) (x - mu_eff)^2 è´´è¿‘å…ˆéªŒä¸­å¿ƒï¼ˆå«æ—¶é—´å¹³æ»‘ï¼‰
    2) lam * x^2       é˜²æç«¯
    3) gamma * NLL     æ¦‚ç‡æ·˜æ±°ä¸€è‡´æ€§
    """
    vote_share = softmax(x)
    elim_score, _ = compute_elim_score_and_extras(int(season), J, vote_share, cfg)

    base = np.sum((x - mu_eff) ** 2) + cfg.lam * np.sum(x ** 2)
    penalty = cfg.gamma * elim_nll(elim_score, elim_indices, tau=cfg.tau)
    return base + penalty

def solve_one_week(df_week: pd.DataFrame, true_elims: list, cfg: Q1Config, prev_x_map: dict | None):
    """
    å¯¹å•ä¸ª (season, week) æ±‚è§£ vote_shareï¼š
    - mu_eff = (1-smooth_w)*mu + smooth_w*prev_xï¼ˆè‹¥ä¸Šä¸€å‘¨å­˜åœ¨ï¼‰
    - åˆå€¼ x0 = mu_effï¼ˆwarm startï¼‰
    """
    season = int(df_week["season"].iloc[0])
    names = df_week["celebrity_name"].astype(str).tolist()
    J = df_week["J"].to_numpy(float)
    mu = df_week["mu"].to_numpy(float)

    # çœŸå®æ·˜æ±°è€…ç´¢å¼•ï¼ˆå¯èƒ½ä¸ºç©º/å¤šä¸ªï¼‰
    elim_indices = [names.index(e) for e in true_elims if e in names]

    # æ—¶é—´å¹³æ»‘åçš„å…ˆéªŒä¸­å¿ƒ mu_eff
    mu_eff = mu.copy()
    if prev_x_map:
        prev_vec = np.array([prev_x_map.get(n, np.nan) for n in names], dtype=float)
        mask = ~np.isnan(prev_vec)
        if mask.any():
            mu_eff[mask] = (1.0 - cfg.smooth_w) * mu[mask] + cfg.smooth_w * prev_vec[mask]

    x0 = mu_eff.copy()
    bounds = [cfg.x_bounds] * len(names)

    res = minimize(
        week_objective,
        x0=x0,
        args=(mu_eff, J, season, elim_indices, cfg),
        method="L-BFGS-B",
        bounds=bounds,
        options={"maxiter": 600},
    )

    x_hat = res.x
    vote_share = softmax(x_hat)
    elim_score, extras = compute_elim_score_and_extras(season, J, vote_share, cfg)

    # é¢„æµ‹æ·˜æ±°ï¼šelim_score æœ€å¤§çš„ k ä¸ªï¼ˆè¶Šå¤§è¶Šå·®ï¼‰
    k = max(1, len(true_elims))
    pred_idx = np.argsort(elim_score)[-k:][::-1]
    pred_elims = [names[i] for i in pred_idx]

    out = df_week[["season", "week", "celebrity_name", "J", "mu"]].copy()
    out["mu_eff"] = mu_eff
    out["vote_share"] = vote_share
    out["votes_scaled"] = vote_share * cfg.scaled_total_votes
    out["rule"] = extras["rule"]
    out["elim_score"] = elim_score

    # Percentage ä¸“å± / Rank ä¸“å±å­—æ®µï¼ˆå¦ä¸€ä¸ªè§„åˆ™ä¸‹ä¸º NaNï¼‰
    out["C"] = extras["C"]
    out["judge_share"] = extras["judge_share"]
    out["judge_rank"] = extras["judge_rank"]
    out["vote_rank"] = extras["vote_rank"]
    out["combined_rank"] = extras["combined_rank"]

    # ä¼˜åŒ–ä¿¡æ¯
    out["opt_success"] = bool(res.success)
    out["opt_fun"] = float(res.fun)

    # çœŸå®/é¢„æµ‹æ·˜æ±°é›†åˆï¼ˆä¾¿äºæ ¸å¯¹ï¼‰
    out["true_elims"] = [true_elims] * len(out)
    out["pred_elims"] = [pred_elims] * len(out)

    # è¿”å› x_hat ä¾›ä¸‹ä¸€å‘¨ warm-startï¼ˆä¸å¿…ä¿å­˜åˆ°æ–‡ä»¶ï¼‰
    return out, {name: float(x) for name, x in zip(names, x_hat)}

def run_all_weeks(week_tbl_mu: pd.DataFrame, elim_by_week: pd.DataFrame, cfg: Q1Config) -> pd.DataFrame:
    """
    éå†æ‰€æœ‰èµ›å­£æ‰€æœ‰å‘¨ï¼Œé€å‘¨æ±‚è§£ï¼Œå¹¶ç”¨ prev_x_map ç»´æŒæ—¶é—´è¿ç»­æ€§
    """
    alive_tbl = week_tbl_mu[week_tbl_mu["alive"] == 1].copy()

    # (season, week) -> true_elims
    elim_map = {(int(r.season), int(r.week)): r.true_elims for r in elim_by_week.itertuples(index=False)}

    outs = []

    for season in sorted(alive_tbl["season"].unique().tolist()):
        gS = alive_tbl[alive_tbl["season"] == season].copy()
        # åªéå†å®é™…æ’­å‡ºå‘¨ï¼ˆalive==1 å‡ºç°çš„å‘¨ï¼‰
        weeks = sorted(gS["week"].unique().tolist())
        prev_map = {}

        for week in weeks:
            gW = gS[gS["week"] == week].copy()
            true_elims = elim_map.get((int(season), int(week)), [])
            out_week, prev_map = solve_one_week(gW, true_elims, cfg, prev_map)
            outs.append(out_week)


    return pd.concat(outs, ignore_index=True)


# ============================================================
# Step 4ï¼šä¸€è‡´æ€§æŒ‡æ ‡
# ============================================================
def week_metrics(df_week_out: pd.DataFrame) -> dict:
    """
    æŒ‡æ ‡å®šä¹‰ï¼š
    - acc_singleï¼šå•æ·˜æ±°å‘¨å‡†ç¡®ç‡
    - cover_bottomkï¼šå¤šæ·˜æ±°å‘¨ bottom-k è¦†ç›–ç‡
    - jaccardï¼šçœŸå®æ·˜æ±°é›†åˆä¸é¢„æµ‹æ·˜æ±°é›†åˆçš„é›†åˆç›¸ä¼¼åº¦
    - delta_marginï¼šelim_score ç¬¬ä¸€ä¸ç¬¬äºŒçš„å·®ï¼ˆè¶Šå°è¡¨ç¤ºè¶Šâ€œä¸´ç•Œ/ä¸ç¡®å®šâ€ï¼‰
    """
    true_elims = df_week_out["true_elims"].iloc[0]
    pred_elims = df_week_out["pred_elims"].iloc[0]
    true_set, pred_set = set(true_elims), set(pred_elims)

    cover = float(true_set.issubset(pred_set)) if true_set else np.nan
    jacc = (len(true_set & pred_set) / len(true_set | pred_set)) if true_set else np.nan
    acc = float(list(true_set)[0] == list(pred_set)[0]) if len(true_set) == 1 else np.nan

    score = df_week_out["elim_score"].to_numpy(float)
    order = np.argsort(score)[::-1]  # å¤§->å°ï¼ˆè¶Šå¤§è¶Šå¯èƒ½æ·˜æ±°ï¼‰
    delta = float(score[order[0]] - score[order[1]]) if len(score) >= 2 else np.nan

    return {"acc_single": acc, "cover_bottomk": cover, "jaccard": jacc, "delta_margin": delta}

def evaluate_all(df_votes: pd.DataFrame) -> pd.DataFrame:
    rows = []
    for (s, w), g in df_votes.groupby(["season", "week"]):
        rows.append({"season": int(s), "week": int(w), **week_metrics(g)})
    return pd.DataFrame(rows).sort_values(["season", "week"]).reset_index(drop=True)


# ============================================================
# Step 5ï¼ˆå¯é€‰ï¼‰ï¼šbootstrap ä¸ç¡®å®šæ€§ï¼ˆåªå»ºè®®å¯¹å°‘æ•°å‘¨åšï¼‰
# ============================================================
def bootstrap_one_week(df_week: pd.DataFrame, true_elims: list, cfg: Q1Config,
                       B=200, sigma_mu=0.15, sigma_J=0.02, seed=0) -> pd.DataFrame:
    """
    å¯¹ä¸€ä¸ª season-week åš bootstrapï¼š
    - mu åŠ å™ªå£°ï¼šæ¨¡æ‹Ÿå…ˆéªŒä¸ç¡®å®š
    - J åŠ ç›¸å¯¹å™ªå£°ï¼šæ¨¡æ‹Ÿè¯„åˆ†è¯¯å·®
    æ¯æ¬¡é‡è§£ï¼Œå¾—åˆ° vote_share åˆ†å¸ƒ
    """
    rng = np.random.default_rng(seed)
    samples = []

    for b in range(B):
        g = df_week.copy()

        g["mu"] = g["mu"] + rng.normal(0.0, sigma_mu, size=len(g))

        J = g["J"].to_numpy(float)
        Jp = J * (1.0 + rng.normal(0.0, sigma_J, size=len(J)))
        g["J"] = np.clip(Jp, 0.0, None)

        out, _ = solve_one_week(g, true_elims, cfg, prev_x_map=None)
        out["b"] = b
        samples.append(out[["season", "week", "celebrity_name", "b", "vote_share", "elim_score", "rule"]])

    return pd.concat(samples, ignore_index=True)

def summarize_bootstrap(bs: pd.DataFrame) -> pd.DataFrame:
    def q(x, p): return float(np.quantile(x, p))
    return (
        bs.groupby(["season", "week", "celebrity_name"])["vote_share"]
          .agg(vote_p05=lambda x: q(x, 0.05),
               vote_p50=lambda x: q(x, 0.50),
               vote_p95=lambda x: q(x, 0.95),
               vote_std="std")
          .reset_index()
    )


# ============================================================
# ä¸»ç¨‹åºï¼šè·‘é€š + ä¿å­˜è¾“å‡º
# ============================================================
def main():
    ensure_dir(OUT_DIR)

    # Step 0
    long_scores = load_raw(CSV_PATH)

    # Step 0.5
    week_tbl = build_week_table(long_scores)

    # Step 1
    season_last, elim_people, elim_by_week = infer_eliminations(week_tbl)

    # Step 2
    week_tbl_mu, _prior_model = fit_prior_mu(week_tbl)

    # Step 3
    cfg = Q1Config(lam=0.1, gamma=120.0, tau=0.02, smooth_w=0.30, scaled_total_votes=1_000_000)
    df_votes = run_all_weeks(week_tbl_mu, elim_by_week, cfg)

    # Step 4
    metrics = evaluate_all(df_votes)

    # ä¿å­˜è¾“å‡º
    out_votes = os.path.join(OUT_DIR, "q1_df_votes.csv")
    out_metrics = os.path.join(OUT_DIR, "q1_metrics.csv")
    out_elims = os.path.join(OUT_DIR, "q1_elim_by_week.csv")
    out_people = os.path.join(OUT_DIR, "q1_elim_people.csv")

    save_csv(df_votes, out_votes)
    save_csv(metrics, out_metrics)
    save_csv(elim_by_week, out_elims)
    save_csv(elim_people, out_people)

    if SAVE_EXCEL:
        save_excel(df_votes, os.path.join(OUT_DIR, "q1_df_votes.xlsx"), "df_votes")
        save_excel(metrics, os.path.join(OUT_DIR, "q1_metrics.xlsx"), "metrics")

    print("âœ… å·²ä¿å­˜ï¼š")
    print(" -", out_votes)
    print(" -", out_metrics)
    print(" -", out_elims)
    print(" -", out_people)

    print("\nğŸ“Œ æŒ‡æ ‡å‡å€¼ï¼ˆå¿«é€Ÿè‡ªæ£€ï¼‰ï¼š")
    print(metrics[["acc_single", "cover_bottomk", "jaccard", "delta_margin"]].mean(numeric_only=True))

    # Step 5ï¼ˆå¯é€‰ï¼‰
    if RUN_BOOTSTRAP:
        df_week = week_tbl_mu[(week_tbl_mu["season"] == BOOTSTRAP_SEASON) &
                              (week_tbl_mu["week"] == BOOTSTRAP_WEEK) &
                              (week_tbl_mu["alive"] == 1)].copy()

        sub = elim_by_week[(elim_by_week["season"] == BOOTSTRAP_SEASON) &
                           (elim_by_week["week"] == BOOTSTRAP_WEEK)]
        true_elims = sub["true_elims"].iloc[0] if len(sub) > 0 else []

        bs = bootstrap_one_week(df_week, true_elims, cfg, B=BOOTSTRAP_B, seed=42)
        bs_summary = summarize_bootstrap(bs)

        out_bs = os.path.join(OUT_DIR, f"q1_bootstrap_summary_s{BOOTSTRAP_SEASON}_w{BOOTSTRAP_WEEK}.csv")
        save_csv(bs_summary, out_bs)
        print("\nâœ… Bootstrap å·²ä¿å­˜ï¼š", out_bs)


if __name__ == "__main__":
    main()